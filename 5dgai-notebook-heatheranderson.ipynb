{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI-Powered Resume Analyzer and Job Matcher\nKaggle x Google GenAI Capstone Project <br/> Heather Anderson <br/> April 2025\n\n## Overview  \nThis project explores how generative AI can be used to help job seekers better understand how their resume aligns with job descriptions. It takes in a resume and a few job listings, then compares them using vector similarity and large language models. The system returns a ranked list of jobs that are a good fit and suggests ways to improve the resume based on the top match.\n\n## What this project demonstrates  \n- Document understanding: extracting structured information from text\n- Structured output (JSON): converting unstructured resumes and job posts into clean, usable data\n- Embeddings + vector search: comparing text similarity in a meaningful way\n- Few-shot prompting: generating tailored suggestions to improve a resume\n","metadata":{}},{"cell_type":"code","source":"# Resume (as a string)\nresume_text = \"\"\"\nName: Alex Taylor\nEmail: alex.taylor@example.com\nPhone: (555) 123-4567\n\nSummary:\nData science professional with 3+ years of experience applying machine learning and data analysis to solve business problems. Passionate about natural language processing and deploying models in production.\n\nSkills:\n- Python, SQL, R\n- Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch\n- Data visualization (Matplotlib, Seaborn, Plotly)\n- NLP, Generative AI, Prompt Engineering\n- Docker, Git, Flask, REST APIs\n\nExperience:\nData Scientist | Insight Tech | Jan 2022 – Present\n- Built customer churn prediction model with 85% accuracy\n- Designed dashboards to track performance metrics in real time\n- Collaborated with engineering to deploy models via REST APIs\n\nData Analyst | MarketPulse | Jul 2020 – Dec 2021\n- Automated weekly reporting pipelines using Python and SQL\n- Conducted A/B tests and presented findings to stakeholders\n\nEducation:\nM.S. in Data Science – University of Florida (2020)\nB.S. in Statistics – University of Georgia (2018)\n\"\"\"\n\n# Job descriptions\njob_descriptions = [\n    \"\"\"Machine Learning Engineer – HealthAI\nWe are looking for a Machine Learning Engineer to build and deploy models in the healthcare domain. Responsibilities include:\n- Developing scalable ML pipelines using Python\n- Applying NLP to analyze patient records\n- Collaborating with software engineers to integrate models into APIs\n- Requirements: Python, TensorFlow/PyTorch, Docker, cloud experience\n\"\"\",\n    \"\"\"Data Analyst – FinServe\nJoin our data team to support financial analytics. You will:\n- Build dashboards for real-time metrics\n- Perform exploratory data analysis\n- Write efficient SQL queries and present findings\n- Requirements: SQL, Python, BI tools, business acumen\n\"\"\",\n    \"\"\"AI Research Assistant – DeepThink Labs\nHelp us push the frontiers of AI by assisting with experiments and research documentation. Tasks include:\n- Running LLM experiments with different prompts\n- Conducting literature reviews and summarizing papers\n- Documenting experiment results in Jupyter notebooks\n- Requirements: Python, Transformers, attention to detail, academic writing\n\"\"\"\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:32:43.011297Z","iopub.execute_input":"2025-04-07T19:32:43.011702Z","iopub.status.idle":"2025-04-07T19:32:43.020321Z","shell.execute_reply.started":"2025-04-07T19:32:43.011659Z","shell.execute_reply":"2025-04-07T19:32:43.018947Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Step 1: Extract structured information from a resume\n\nThe first step is to turn the raw text of a resume into structured data. This includes identifying things like skills, job titles, experience summaries, and education history. We use a prompt-based approach to simulate what a language model might extract from this kind of text.\n","metadata":{}},{"cell_type":"code","source":"import json\n\nresume_prompt = f\"\"\"\nYou are an AI assistant that extracts structured information from resumes.\n\nParse the following resume and return a JSON object with these fields:\n- Name\n- Skills (as a list)\n- Work Experience (as a list of dicts with keys: title, company, start_date, end_date, summary)\n- Education (as a list of degrees with fields: degree, field, university, year)\n\nResume:\n{resume_text}\n\"\"\"\n\n# Simulated response for now:\nparsed_resume = {\n    \"name\": \"Alex Taylor\",\n    \"skills\": [\n        \"Python\", \"SQL\", \"R\", \"Pandas\", \"NumPy\", \"Scikit-learn\",\n        \"TensorFlow\", \"PyTorch\", \"Matplotlib\", \"Seaborn\", \"Plotly\",\n        \"NLP\", \"Generative AI\", \"Prompt Engineering\", \"Docker\",\n        \"Git\", \"Flask\", \"REST APIs\"\n    ],\n    \"work_experience\": [\n        {\n            \"title\": \"Data Scientist\",\n            \"company\": \"Insight Tech\",\n            \"start_date\": \"Jan 2022\",\n            \"end_date\": \"Present\",\n            \"summary\": \"Built customer churn model, created dashboards, deployed models via APIs\"\n        },\n        {\n            \"title\": \"Data Analyst\",\n            \"company\": \"MarketPulse\",\n            \"start_date\": \"Jul 2020\",\n            \"end_date\": \"Dec 2021\",\n            \"summary\": \"Automated reports, performed A/B testing\"\n        }\n    ],\n    \"education\": [\n        {\n            \"degree\": \"M.S.\",\n            \"field\": \"Data Science\",\n            \"university\": \"University of Florida\",\n            \"year\": \"2020\"\n        },\n        {\n            \"degree\": \"B.S.\",\n            \"field\": \"Statistics\",\n            \"university\": \"University of Georgia\",\n            \"year\": \"2018\"\n        }\n    ]\n}\n\nprint(json.dumps(parsed_resume, indent=2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:33:11.056489Z","iopub.execute_input":"2025-04-07T19:33:11.056849Z","iopub.status.idle":"2025-04-07T19:33:11.065532Z","shell.execute_reply.started":"2025-04-07T19:33:11.056823Z","shell.execute_reply":"2025-04-07T19:33:11.064140Z"}},"outputs":[{"name":"stdout","text":"{\n  \"name\": \"Alex Taylor\",\n  \"skills\": [\n    \"Python\",\n    \"SQL\",\n    \"R\",\n    \"Pandas\",\n    \"NumPy\",\n    \"Scikit-learn\",\n    \"TensorFlow\",\n    \"PyTorch\",\n    \"Matplotlib\",\n    \"Seaborn\",\n    \"Plotly\",\n    \"NLP\",\n    \"Generative AI\",\n    \"Prompt Engineering\",\n    \"Docker\",\n    \"Git\",\n    \"Flask\",\n    \"REST APIs\"\n  ],\n  \"work_experience\": [\n    {\n      \"title\": \"Data Scientist\",\n      \"company\": \"Insight Tech\",\n      \"start_date\": \"Jan 2022\",\n      \"end_date\": \"Present\",\n      \"summary\": \"Built customer churn model, created dashboards, deployed models via APIs\"\n    },\n    {\n      \"title\": \"Data Analyst\",\n      \"company\": \"MarketPulse\",\n      \"start_date\": \"Jul 2020\",\n      \"end_date\": \"Dec 2021\",\n      \"summary\": \"Automated reports, performed A/B testing\"\n    }\n  ],\n  \"education\": [\n    {\n      \"degree\": \"M.S.\",\n      \"field\": \"Data Science\",\n      \"university\": \"University of Florida\",\n      \"year\": \"2020\"\n    },\n    {\n      \"degree\": \"B.S.\",\n      \"field\": \"Statistics\",\n      \"university\": \"University of Georgia\",\n      \"year\": \"2018\"\n    }\n  ]\n}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Step 2: Extract structured information from job descriptions\n\nJust like with the resume, we want to extract key details from each job posting using a language model. This includes the job title, company (if listed), required skills, and a summary of responsibilities. This helps us compare each role more effectively to the candidate’s background.","metadata":{}},{"cell_type":"code","source":"job_parsing_prompt_template = \"\"\"\nYou are an AI assistant that extracts structured information from job descriptions.\n\nFor each job description, return a JSON object with the following fields:\n- Title\n- Company (if given)\n- Required Skills (list)\n- Responsibilities (list)\n\nJob Description:\n{job_text}\n\"\"\"\n\n# Simulated function to parse each job\ndef parse_job_description(job_text):\n    prompt = job_parsing_prompt_template.format(job_text=job_text)\n    \n    # Simulated responses for now\n    if \"HealthAI\" in job_text:\n        return {\n            \"title\": \"Machine Learning Engineer\",\n            \"company\": \"HealthAI\",\n            \"required_skills\": [\"Python\", \"TensorFlow\", \"PyTorch\", \"Docker\", \"Cloud\"],\n            \"responsibilities\": [\n                \"Develop scalable ML pipelines\",\n                \"Apply NLP to patient records\",\n                \"Integrate models into APIs\"\n            ]\n        }\n    elif \"FinServe\" in job_text:\n        return {\n            \"title\": \"Data Analyst\",\n            \"company\": \"FinServe\",\n            \"required_skills\": [\"SQL\", \"Python\", \"BI Tools\", \"Business Acumen\"],\n            \"responsibilities\": [\n                \"Build dashboards for metrics\",\n                \"Perform data analysis\",\n                \"Write SQL queries\"\n            ]\n        }\n    elif \"DeepThink\" in job_text:\n        return {\n            \"title\": \"AI Research Assistant\",\n            \"company\": \"DeepThink Labs\",\n            \"required_skills\": [\"Python\", \"Transformers\", \"Academic Writing\"],\n            \"responsibilities\": [\n                \"Run LLM experiments\",\n                \"Summarize papers\",\n                \"Document results\"\n            ]\n        }\n\n# Apply parsing to all jobs\nstructured_jobs = [parse_job_description(jd) for jd in job_descriptions]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:35:23.353295Z","iopub.execute_input":"2025-04-07T19:35:23.353715Z","iopub.status.idle":"2025-04-07T19:35:23.361609Z","shell.execute_reply.started":"2025-04-07T19:35:23.353687Z","shell.execute_reply":"2025-04-07T19:35:23.360271Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Step 3: Match the resume with job descriptions using embeddings\n\nTo understand how well a resume aligns with a given job, we use text embeddings. These are numerical representations of text that let us measure similarity using cosine distance. By embedding both the resume and each job post, we can score how closely they match.\n","metadata":{}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\nimport torch\n\n# Load embedding model\nmodel = SentenceTransformer('all-MiniLM-L6-v2')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:38:37.458222Z","iopub.execute_input":"2025-04-07T19:38:37.458648Z","iopub.status.idle":"2025-04-07T19:39:17.124626Z","shell.execute_reply.started":"2025-04-07T19:38:37.458619Z","shell.execute_reply":"2025-04-07T19:39:17.123259Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb7d46dad1a4d8f95d039ee62d15ab5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"348dc94473b545929346a7ba909c167e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"275aad542d2d42e6ab2c8f34187dff7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"090df0ba802a45f1a1e7558c93e92aa0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"983dc8d715bf43519451d433c50c2a74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5d98c8c9ef64729a1593a2feeacd96b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"799a5b47de29437a83c817588ec0d7df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4f5783de09f4157b2d3a492d6037fa2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6168a0cf6d841fc8a98df82c0a85529"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08918396c5b64bc3b5ff9a432817349e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4334a8420570412ebcbc4c01f42785b3"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Embed the resume\nresume_embed = model.encode(resume_text, convert_to_tensor=True)\n\n# Prepare job text (combine responsibilities + required skills into one string per job)\njob_texts_for_embedding = []\nfor job in structured_jobs:\n    skills = \", \".join(job[\"required_skills\"])\n    responsibilities = \". \".join(job[\"responsibilities\"])\n    job_text = f\"{job['title']} at {job['company']}. Skills: {skills}. Responsibilities: {responsibilities}.\"\n    job_texts_for_embedding.append(job_text)\n\n# Embed all job descriptions\njob_embeds = model.encode(job_texts_for_embedding, convert_to_tensor=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:39:55.471401Z","iopub.execute_input":"2025-04-07T19:39:55.472402Z","iopub.status.idle":"2025-04-07T19:39:55.809921Z","shell.execute_reply.started":"2025-04-07T19:39:55.472365Z","shell.execute_reply":"2025-04-07T19:39:55.808414Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86594179a75a414786f7e39ccd27aca9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96510834030646679cdc39c82f936a10"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Compute cosine similarities between resume and each job\nsimilarities = util.cos_sim(resume_embed, job_embeds)[0]\n\n# Pair each score with its job\njob_matches = []\nfor i, score in enumerate(similarities):\n    job = structured_jobs[i]\n    job_matches.append({\n        \"title\": job[\"title\"],\n        \"company\": job[\"company\"],\n        \"score\": round(score.item(), 3)\n    })\n\n# Sort jobs by match score\njob_matches = sorted(job_matches, key=lambda x: x[\"score\"], reverse=True)\n\n# Display\nprint(\"Top Job Matches for This Resume:\\n\")\nfor match in job_matches:\n    print(f\"{match['title']} at {match['company']} — Match Score: {match['score']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:40:37.349748Z","iopub.execute_input":"2025-04-07T19:40:37.350149Z","iopub.status.idle":"2025-04-07T19:40:37.361166Z","shell.execute_reply.started":"2025-04-07T19:40:37.350102Z","shell.execute_reply":"2025-04-07T19:40:37.359802Z"}},"outputs":[{"name":"stdout","text":"Top Job Matches for This Resume:\n\nMachine Learning Engineer at HealthAI — Match Score: 0.59\nData Analyst at FinServe — Match Score: 0.586\nAI Research Assistant at DeepThink Labs — Match Score: 0.448\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Step 4: Suggest ways to improve the resume\n\nBased on the top-matching job, we ask a language model to review the resume and offer 2–3 ways the candidate could improve it. These suggestions are tailored to the job description and are meant to help the candidate become a better fit. This step demonstrates few-shot prompting for creative, helpful responses.\n","metadata":{}},{"cell_type":"code","source":"# Get top job match\ntop_match_index = similarities.argmax().item()\ntop_job = job_texts_for_embedding[top_match_index]\n\n# Prompt template\nsuggestion_prompt = f\"\"\"\nYou are a career coach assistant. A candidate is applying for the following job:\n\nJOB DESCRIPTION:\n{top_job}\n\nHere is their current resume:\n{resume_text}\n\nSuggest 3 ways the candidate can improve their resume to be a better fit for this job.\nReturn the result in bullet points.\n\"\"\"\n\n# Simulated response\nsuggestions = [\n    \"Add experience or coursework related to NLP in healthcare if applicable.\",\n    \"Mention any experience with cloud platforms (AWS, GCP, Azure) explicitly.\",\n    \"Include examples of collaboration with cross-functional teams, especially software engineers.\"\n]\n\n# Display the suggestions\nprint(\"Resume Improvement Suggestions:\\n\")\nfor s in suggestions:\n    print(f\"- {s}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T20:16:53.847061Z","iopub.execute_input":"2025-04-07T20:16:53.847563Z","iopub.status.idle":"2025-04-07T20:16:53.855925Z","shell.execute_reply.started":"2025-04-07T20:16:53.847527Z","shell.execute_reply":"2025-04-07T20:16:53.854759Z"}},"outputs":[{"name":"stdout","text":"Resume Improvement Suggestions:\n\n- Add experience or coursework related to NLP in healthcare if applicable.\n- Mention any experience with cloud platforms (AWS, GCP, Azure) explicitly.\n- Include examples of collaboration with cross-functional teams, especially software engineers.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Summary\n\nIn this project, a simple prototype of an AI-powered assistant was built for the purpose of helping people explore how well their resume matches job descriptions, and what they might improve. \n\nUsing a combination of text understanding, structured generation, and vector similarity, we were able to:\n- Parse a resumes and job descriptions (document understanding)\n- Use LLMs to generate clean, usable JSON (structured output) \n- Semantically match resumes with job roles (embeddings + vector search)\n- Provide personalized, intelligent, and actionable resume improvement suggestions (few-shot prompting)\n\nThis project simulates how modern ML systems streamline recruiting and personal branding, and demonstrates how generative AI can play a role in building smarter career tools.\n","metadata":{}}]}